#!/usr/bin/env python3
# author: daniel rode
# dependencies: podman, podman-compose, aria2
# created: 07 feb 2026
# updated: 18 feb 2026


# Transcribe audio locally via whisper.cpp.
#
# USAGE: wcpp FILE.wav | rg ' \[\d\d:\d\d:\d\d\.\d\d\d --> \d\d:\d\d:\d\d\.\d\d\d\] ' | cut -c61-
# USAGE: mic2wav tmp.wav; wcpp tmp.wav
#
# TODO Consider https://github.com/istupakov/onnx-asr as alternative (can use the better Parakeet model with it).


import sys
import subprocess as sp
from pathlib import Path

import yaml


DEFAULT_MODEL = 'ggml-small.en.bin'
MODEL_URL_MAP = {i.split('/')[-1]:i for i in (
    # Model list: https://huggingface.co/ggerganov/whisper.cpp/tree/main
    # More models?: https://huggingface.co/models?search=whisper%20ggml
    'https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-tiny.en.bin',
    'https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-small.en.bin',
)}


HOME = Path.home()
CACHE_DIR = HOME / ".cache"

MODEL_DIR = CACHE_DIR / "com.github.danielrode/wcpp/models"

def get_con_yaml(model_filename, audio_path):
    audio_path_fmt = audio_path
    if not str(audio_path).startswith('/'):
        audio_path_fmt = './' + str(audio_path)
    return yaml.dump({
        'version': 3.2,
        'services': {
            'whispercpp': {
                # 'image': 'ghcr.io/ggml-org/whisper.cpp:main',
                'image': 'ghcr.io/ggml-org/whisper.cpp:main-vulkan',
                'devices': [
                    '/dev/dri',
                ],
                'volumes': [
                    str(MODEL_DIR) + ':/models:ro,z',
                    str(audio_path_fmt) + ':/audios/' + audio_path.name + \
                        ':ro,z',
                ],
                'entrypoint': 'whisper-cli',
                'command': [
                    # '--help',
                    '-m', '/models/' + model_filename,
                    '-f', '/audios/' + audio_path.name,
                    # '--no-prints',
                    # '--print-colors',
                ],
            },
        },
    })


# Main

# Parse command line input
model_filename = DEFAULT_MODEL
# TODO add flag processing so you can pass '-m NAME' to change model used
try:
    audio_path = Path(sys.argv[1])
except IndexError:
    print("error: Provide path to audio file")
    sys.exit(1)

if model_filename not in MODEL_URL_MAP:
    print("error: Model not found:", model_filename)
    sys.exit(1)

# Download model, if needed
if not (MODEL_DIR / model_filename).exists():
    print("Model file not found; downloading...")
    MODEL_DIR.mkdir(exist_ok=True, parents=True)
    cmd = (
        'aria2c',
        '--dir', str(MODEL_DIR),
        '--out', model_filename,
        MODEL_URL_MAP[model_filename],
    )
    sp.run(cmd, check=True)

# Run whisper.cpp
cmd = (
    'podman-compose',
    '--file', '-',
    'up',
)
con_yaml = get_con_yaml(model_filename, audio_path)
sp.run(cmd, input=con_yaml, text=True)
