#!/usr/bin/env bash
# author: daniel rode
# dependencies: podman, podman-compose
# created: 01 dec 2025
# updated: 22 jan 2026


# Run LLMs (AI chat) locally via Koboldcpp.


COMPOSE_YAML_PATH=~/code/etc/con/compose/kcpp.yaml
ENV_PATH=~/llms/kcpp/vars.env
GGUF_MODEL_DIR=~/llms/gguf


function fail {
    echo -n "error: "
    echo "$1"
    exit 1
}


[[ ! -d "$GGUF_MODEL_DIR" ]] && fail "Model directory does not exist"
[[ ! -f "$ENV_PATH" ]] && fail "Koboldcpp credential/settings file not found"

mkdir -p "$HOME/.appdata/kcpp"
podman-compose --file "$COMPOSE_YAML_PATH" --env-file "$ENV_PATH" up

cat <<EOF
On your remote workstation, run:
ssh -NL 50001:localhost:50001 SERVER_USER@SERVER_IP
Then go to http://localhost:50001
EOF
